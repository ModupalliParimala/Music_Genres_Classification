{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Genres_classification_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMsbV0Lagqpu4+fUBkEXnMS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ModupalliParimala/Music_Genres_Classification/blob/main/Music_Genres_classification_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sqCSUenbDtk",
        "outputId": "48a95345-742c-4182-f13c-2dc518c6f778"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm8Eqbqgca9A",
        "outputId": "46afa02a-2041-4c1a-e345-76f7e4c93ca3"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Deep_Learning/Projects/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Deep_Learning/Projects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYhwGD2WfRC5"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--HAzFJwcxxK",
        "outputId": "21bf9cf6-156e-4887-c739-f435c0fae8f5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import  StandardScaler,LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Activation,Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnL-3QqfcpEK"
      },
      "source": [
        "# Loading Data from csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "Sg5RZcicb9-x",
        "outputId": "d16bb4ef-0af4-4e18-a606-f6c8017870b4"
      },
      "source": [
        "audio_data = pd.read_csv('Extracted_features.csv')\n",
        "audio_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>chroma_stft</th>\n",
              "      <th>rmse</th>\n",
              "      <th>spectral_centroid</th>\n",
              "      <th>spectral_bandwidth</th>\n",
              "      <th>rolloff</th>\n",
              "      <th>zero_crossing_rate</th>\n",
              "      <th>mfcc1</th>\n",
              "      <th>mfcc2</th>\n",
              "      <th>mfcc3</th>\n",
              "      <th>mfcc4</th>\n",
              "      <th>mfcc5</th>\n",
              "      <th>mfcc6</th>\n",
              "      <th>mfcc7</th>\n",
              "      <th>mfcc8</th>\n",
              "      <th>mfcc9</th>\n",
              "      <th>mfcc10</th>\n",
              "      <th>mfcc11</th>\n",
              "      <th>mfcc12</th>\n",
              "      <th>mfcc13</th>\n",
              "      <th>mfcc14</th>\n",
              "      <th>mfcc15</th>\n",
              "      <th>mfcc16</th>\n",
              "      <th>mfcc17</th>\n",
              "      <th>mfcc18</th>\n",
              "      <th>mfcc19</th>\n",
              "      <th>mfcc20</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blues.00000.wav</td>\n",
              "      <td>0.349943</td>\n",
              "      <td>0.130225</td>\n",
              "      <td>1784.420446</td>\n",
              "      <td>2002.650192</td>\n",
              "      <td>3806.485316</td>\n",
              "      <td>0.083066</td>\n",
              "      <td>-113.596748</td>\n",
              "      <td>121.557297</td>\n",
              "      <td>-19.158825</td>\n",
              "      <td>42.351032</td>\n",
              "      <td>-6.376458</td>\n",
              "      <td>18.618876</td>\n",
              "      <td>-13.697912</td>\n",
              "      <td>15.344631</td>\n",
              "      <td>-12.285267</td>\n",
              "      <td>10.980492</td>\n",
              "      <td>-8.324325</td>\n",
              "      <td>8.810669</td>\n",
              "      <td>-3.667368</td>\n",
              "      <td>5.751691</td>\n",
              "      <td>-5.162763</td>\n",
              "      <td>0.750948</td>\n",
              "      <td>-1.691938</td>\n",
              "      <td>-0.409953</td>\n",
              "      <td>-2.300209</td>\n",
              "      <td>1.219929</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blues.00001.wav</td>\n",
              "      <td>0.340983</td>\n",
              "      <td>0.095918</td>\n",
              "      <td>1529.835316</td>\n",
              "      <td>2038.617579</td>\n",
              "      <td>3548.820207</td>\n",
              "      <td>0.056044</td>\n",
              "      <td>-207.556793</td>\n",
              "      <td>124.006721</td>\n",
              "      <td>8.930560</td>\n",
              "      <td>35.874687</td>\n",
              "      <td>2.916037</td>\n",
              "      <td>21.523726</td>\n",
              "      <td>-8.554704</td>\n",
              "      <td>23.358671</td>\n",
              "      <td>-10.103617</td>\n",
              "      <td>11.903744</td>\n",
              "      <td>-5.560388</td>\n",
              "      <td>5.376803</td>\n",
              "      <td>-2.239120</td>\n",
              "      <td>4.216963</td>\n",
              "      <td>-6.012273</td>\n",
              "      <td>0.936110</td>\n",
              "      <td>-0.716537</td>\n",
              "      <td>0.293876</td>\n",
              "      <td>-0.287431</td>\n",
              "      <td>0.531573</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blues.00002.wav</td>\n",
              "      <td>0.363603</td>\n",
              "      <td>0.175573</td>\n",
              "      <td>1552.481958</td>\n",
              "      <td>1747.165985</td>\n",
              "      <td>3040.514948</td>\n",
              "      <td>0.076301</td>\n",
              "      <td>-90.754387</td>\n",
              "      <td>140.459900</td>\n",
              "      <td>-29.109968</td>\n",
              "      <td>31.689013</td>\n",
              "      <td>-13.987036</td>\n",
              "      <td>25.754759</td>\n",
              "      <td>-13.649585</td>\n",
              "      <td>11.629271</td>\n",
              "      <td>-11.780589</td>\n",
              "      <td>9.706443</td>\n",
              "      <td>-13.123111</td>\n",
              "      <td>5.789265</td>\n",
              "      <td>-8.905224</td>\n",
              "      <td>-1.083720</td>\n",
              "      <td>-9.218359</td>\n",
              "      <td>2.455806</td>\n",
              "      <td>-7.726901</td>\n",
              "      <td>-1.815723</td>\n",
              "      <td>-3.433434</td>\n",
              "      <td>-2.226821</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blues.00003.wav</td>\n",
              "      <td>0.404779</td>\n",
              "      <td>0.141191</td>\n",
              "      <td>1070.119953</td>\n",
              "      <td>1596.333948</td>\n",
              "      <td>2185.028454</td>\n",
              "      <td>0.033309</td>\n",
              "      <td>-199.431152</td>\n",
              "      <td>150.099213</td>\n",
              "      <td>5.647593</td>\n",
              "      <td>26.871927</td>\n",
              "      <td>1.754462</td>\n",
              "      <td>14.238345</td>\n",
              "      <td>-4.830883</td>\n",
              "      <td>9.297966</td>\n",
              "      <td>-0.757742</td>\n",
              "      <td>8.149013</td>\n",
              "      <td>-3.196314</td>\n",
              "      <td>6.087677</td>\n",
              "      <td>-2.476421</td>\n",
              "      <td>-1.073890</td>\n",
              "      <td>-2.874778</td>\n",
              "      <td>0.780977</td>\n",
              "      <td>-3.316932</td>\n",
              "      <td>0.637982</td>\n",
              "      <td>-0.619690</td>\n",
              "      <td>-3.408233</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blues.00004.wav</td>\n",
              "      <td>0.308590</td>\n",
              "      <td>0.091563</td>\n",
              "      <td>1835.494603</td>\n",
              "      <td>1748.362448</td>\n",
              "      <td>3580.945013</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>-160.266037</td>\n",
              "      <td>126.198799</td>\n",
              "      <td>-35.605450</td>\n",
              "      <td>22.153301</td>\n",
              "      <td>-32.489265</td>\n",
              "      <td>10.864513</td>\n",
              "      <td>-23.357929</td>\n",
              "      <td>0.503118</td>\n",
              "      <td>-11.805833</td>\n",
              "      <td>1.206805</td>\n",
              "      <td>-13.083821</td>\n",
              "      <td>-2.806384</td>\n",
              "      <td>-6.934123</td>\n",
              "      <td>-7.558618</td>\n",
              "      <td>-9.173553</td>\n",
              "      <td>-4.512165</td>\n",
              "      <td>-5.453538</td>\n",
              "      <td>-0.924161</td>\n",
              "      <td>-4.409332</td>\n",
              "      <td>-11.703781</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename  chroma_stft      rmse  ...    mfcc19     mfcc20  label\n",
              "0  blues.00000.wav     0.349943  0.130225  ... -2.300209   1.219929  blues\n",
              "1  blues.00001.wav     0.340983  0.095918  ... -0.287431   0.531573  blues\n",
              "2  blues.00002.wav     0.363603  0.175573  ... -3.433434  -2.226821  blues\n",
              "3  blues.00003.wav     0.404779  0.141191  ... -0.619690  -3.408233  blues\n",
              "4  blues.00004.wav     0.308590  0.091563  ... -4.409332 -11.703781  blues\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "O5ZTrRtRdLlz",
        "outputId": "1db3c0b9-46e0-4084-96e9-e586f85955e9"
      },
      "source": [
        "#Filename column is not required.so dropping it\n",
        "# Dropping unneccesary columns\n",
        "audio_data.drop(['filename'],axis=1,inplace=True)\n",
        "audio_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chroma_stft</th>\n",
              "      <th>rmse</th>\n",
              "      <th>spectral_centroid</th>\n",
              "      <th>spectral_bandwidth</th>\n",
              "      <th>rolloff</th>\n",
              "      <th>zero_crossing_rate</th>\n",
              "      <th>mfcc1</th>\n",
              "      <th>mfcc2</th>\n",
              "      <th>mfcc3</th>\n",
              "      <th>mfcc4</th>\n",
              "      <th>mfcc5</th>\n",
              "      <th>mfcc6</th>\n",
              "      <th>mfcc7</th>\n",
              "      <th>mfcc8</th>\n",
              "      <th>mfcc9</th>\n",
              "      <th>mfcc10</th>\n",
              "      <th>mfcc11</th>\n",
              "      <th>mfcc12</th>\n",
              "      <th>mfcc13</th>\n",
              "      <th>mfcc14</th>\n",
              "      <th>mfcc15</th>\n",
              "      <th>mfcc16</th>\n",
              "      <th>mfcc17</th>\n",
              "      <th>mfcc18</th>\n",
              "      <th>mfcc19</th>\n",
              "      <th>mfcc20</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.349943</td>\n",
              "      <td>0.130225</td>\n",
              "      <td>1784.420446</td>\n",
              "      <td>2002.650192</td>\n",
              "      <td>3806.485316</td>\n",
              "      <td>0.083066</td>\n",
              "      <td>-113.596748</td>\n",
              "      <td>121.557297</td>\n",
              "      <td>-19.158825</td>\n",
              "      <td>42.351032</td>\n",
              "      <td>-6.376458</td>\n",
              "      <td>18.618876</td>\n",
              "      <td>-13.697912</td>\n",
              "      <td>15.344631</td>\n",
              "      <td>-12.285267</td>\n",
              "      <td>10.980492</td>\n",
              "      <td>-8.324325</td>\n",
              "      <td>8.810669</td>\n",
              "      <td>-3.667368</td>\n",
              "      <td>5.751691</td>\n",
              "      <td>-5.162763</td>\n",
              "      <td>0.750948</td>\n",
              "      <td>-1.691938</td>\n",
              "      <td>-0.409953</td>\n",
              "      <td>-2.300209</td>\n",
              "      <td>1.219929</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.340983</td>\n",
              "      <td>0.095918</td>\n",
              "      <td>1529.835316</td>\n",
              "      <td>2038.617579</td>\n",
              "      <td>3548.820207</td>\n",
              "      <td>0.056044</td>\n",
              "      <td>-207.556793</td>\n",
              "      <td>124.006721</td>\n",
              "      <td>8.930560</td>\n",
              "      <td>35.874687</td>\n",
              "      <td>2.916037</td>\n",
              "      <td>21.523726</td>\n",
              "      <td>-8.554704</td>\n",
              "      <td>23.358671</td>\n",
              "      <td>-10.103617</td>\n",
              "      <td>11.903744</td>\n",
              "      <td>-5.560388</td>\n",
              "      <td>5.376803</td>\n",
              "      <td>-2.239120</td>\n",
              "      <td>4.216963</td>\n",
              "      <td>-6.012273</td>\n",
              "      <td>0.936110</td>\n",
              "      <td>-0.716537</td>\n",
              "      <td>0.293876</td>\n",
              "      <td>-0.287431</td>\n",
              "      <td>0.531573</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.363603</td>\n",
              "      <td>0.175573</td>\n",
              "      <td>1552.481958</td>\n",
              "      <td>1747.165985</td>\n",
              "      <td>3040.514948</td>\n",
              "      <td>0.076301</td>\n",
              "      <td>-90.754387</td>\n",
              "      <td>140.459900</td>\n",
              "      <td>-29.109968</td>\n",
              "      <td>31.689013</td>\n",
              "      <td>-13.987036</td>\n",
              "      <td>25.754759</td>\n",
              "      <td>-13.649585</td>\n",
              "      <td>11.629271</td>\n",
              "      <td>-11.780589</td>\n",
              "      <td>9.706443</td>\n",
              "      <td>-13.123111</td>\n",
              "      <td>5.789265</td>\n",
              "      <td>-8.905224</td>\n",
              "      <td>-1.083720</td>\n",
              "      <td>-9.218359</td>\n",
              "      <td>2.455806</td>\n",
              "      <td>-7.726901</td>\n",
              "      <td>-1.815723</td>\n",
              "      <td>-3.433434</td>\n",
              "      <td>-2.226821</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.404779</td>\n",
              "      <td>0.141191</td>\n",
              "      <td>1070.119953</td>\n",
              "      <td>1596.333948</td>\n",
              "      <td>2185.028454</td>\n",
              "      <td>0.033309</td>\n",
              "      <td>-199.431152</td>\n",
              "      <td>150.099213</td>\n",
              "      <td>5.647593</td>\n",
              "      <td>26.871927</td>\n",
              "      <td>1.754462</td>\n",
              "      <td>14.238345</td>\n",
              "      <td>-4.830883</td>\n",
              "      <td>9.297966</td>\n",
              "      <td>-0.757742</td>\n",
              "      <td>8.149013</td>\n",
              "      <td>-3.196314</td>\n",
              "      <td>6.087677</td>\n",
              "      <td>-2.476421</td>\n",
              "      <td>-1.073890</td>\n",
              "      <td>-2.874778</td>\n",
              "      <td>0.780977</td>\n",
              "      <td>-3.316932</td>\n",
              "      <td>0.637982</td>\n",
              "      <td>-0.619690</td>\n",
              "      <td>-3.408233</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.308590</td>\n",
              "      <td>0.091563</td>\n",
              "      <td>1835.494603</td>\n",
              "      <td>1748.362448</td>\n",
              "      <td>3580.945013</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>-160.266037</td>\n",
              "      <td>126.198799</td>\n",
              "      <td>-35.605450</td>\n",
              "      <td>22.153301</td>\n",
              "      <td>-32.489265</td>\n",
              "      <td>10.864513</td>\n",
              "      <td>-23.357929</td>\n",
              "      <td>0.503118</td>\n",
              "      <td>-11.805833</td>\n",
              "      <td>1.206805</td>\n",
              "      <td>-13.083821</td>\n",
              "      <td>-2.806384</td>\n",
              "      <td>-6.934123</td>\n",
              "      <td>-7.558618</td>\n",
              "      <td>-9.173553</td>\n",
              "      <td>-4.512165</td>\n",
              "      <td>-5.453538</td>\n",
              "      <td>-0.924161</td>\n",
              "      <td>-4.409332</td>\n",
              "      <td>-11.703781</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   chroma_stft      rmse  spectral_centroid  ...    mfcc19     mfcc20  label\n",
              "0     0.349943  0.130225        1784.420446  ... -2.300209   1.219929  blues\n",
              "1     0.340983  0.095918        1529.835316  ... -0.287431   0.531573  blues\n",
              "2     0.363603  0.175573        1552.481958  ... -3.433434  -2.226821  blues\n",
              "3     0.404779  0.141191        1070.119953  ... -0.619690  -3.408233  blues\n",
              "4     0.308590  0.091563        1835.494603  ... -4.409332 -11.703781  blues\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckoKMQ_Eeq4M",
        "outputId": "bebec36e-3393-4498-da2f-ec096059eed6"
      },
      "source": [
        "audio_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGroDEr6dnz2",
        "outputId": "95205e89-35ee-4658-f50a-b6f38a6be685"
      },
      "source": [
        "audio_data.iloc[:, -1].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pop          100\n",
              "hiphop       100\n",
              "metal        100\n",
              "rock         100\n",
              "reggae       100\n",
              "country      100\n",
              "classical    100\n",
              "jazz         100\n",
              "blues        100\n",
              "disco        100\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CYECkE4vARi",
        "outputId": "06329346-857a-4db9-b3fc-a1fab739f34a"
      },
      "source": [
        "#encode genres into integers.Each integer represents the specific genre.\n",
        "genre_list = audio_data.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(genre_list)\n",
        "y = to_categorical(y,num_classes=10)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYs9XNdtv0Xu",
        "outputId": "cf2243c9-8c2a-4bcf-8435-e9c53f725427"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc-fFedieJOy"
      },
      "source": [
        "# Normalizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLzi_cameLWB"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(np.array(audio_data.iloc[:, :-1], dtype = float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7NFD06YeSDO"
      },
      "source": [
        "# Splitting dataset into Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o80QBvf1eVpG"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exw1MMGxedhB",
        "outputId": "9a1d5775-7db9-4242-ef90-dfa4a8f4b964"
      },
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800, 26), (800, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1VcCjPteixT",
        "outputId": "0058a830-5365-44e7-ac1d-00850c7018a8"
      },
      "source": [
        "X_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((200, 26), (200, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YlfgYHWgPEX",
        "outputId": "9e683228-8d81-4f79-8e49-18df31c927f4"
      },
      "source": [
        "X_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMwa-0Jve1Et"
      },
      "source": [
        "#Building ANN(also known as Feed Forward Network)\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhzeoKxKhal8",
        "outputId": "1f66a5a0-4ac7-4213-8337-e4aa05395c4b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               13824     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 186,954\n",
            "Trainable params: 186,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "YRgiO3jFjuC4",
        "outputId": "4e747198-fac1-4a36-b039-ef7edebc3773"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CxNBfNpgTZ4"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC85r0ZXgkiF",
        "outputId": "37559bf1-7062-41a0-cb93-158e8af96652"
      },
      "source": [
        "# if the accuracy does not increase over 10 epochs, reduce the learning rate by half.\n",
        "reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=200,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[reduce_lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 2.0768 - accuracy: 0.2837 - val_loss: 1.4716 - val_accuracy: 0.4500\n",
            "Epoch 2/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 1.3352 - accuracy: 0.5132 - val_loss: 1.2617 - val_accuracy: 0.5850\n",
            "Epoch 3/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 1.1161 - accuracy: 0.6092 - val_loss: 1.0776 - val_accuracy: 0.6050\n",
            "Epoch 4/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.9733 - accuracy: 0.6383 - val_loss: 1.0859 - val_accuracy: 0.6200\n",
            "Epoch 5/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.8015 - accuracy: 0.7482 - val_loss: 1.0183 - val_accuracy: 0.6400\n",
            "Epoch 6/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.7303 - accuracy: 0.7621 - val_loss: 0.9390 - val_accuracy: 0.6950\n",
            "Epoch 7/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5829 - accuracy: 0.8015 - val_loss: 0.9776 - val_accuracy: 0.6250\n",
            "Epoch 8/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.8364 - val_loss: 0.9728 - val_accuracy: 0.6750\n",
            "Epoch 9/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.8622 - val_loss: 0.9023 - val_accuracy: 0.6950\n",
            "Epoch 10/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8822 - val_loss: 0.9908 - val_accuracy: 0.6650\n",
            "Epoch 11/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3385 - accuracy: 0.8853 - val_loss: 1.0351 - val_accuracy: 0.7000\n",
            "Epoch 12/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3217 - accuracy: 0.8904 - val_loss: 0.9454 - val_accuracy: 0.7000\n",
            "Epoch 13/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2112 - accuracy: 0.9498 - val_loss: 0.8925 - val_accuracy: 0.7150\n",
            "Epoch 14/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9567 - val_loss: 1.0807 - val_accuracy: 0.6950\n",
            "Epoch 15/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1614 - accuracy: 0.9600 - val_loss: 1.0702 - val_accuracy: 0.7050\n",
            "Epoch 16/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.9635 - val_loss: 1.1440 - val_accuracy: 0.6900\n",
            "Epoch 17/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9655 - val_loss: 1.1410 - val_accuracy: 0.6900\n",
            "Epoch 18/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1061 - accuracy: 0.9751 - val_loss: 1.0778 - val_accuracy: 0.7250\n",
            "Epoch 19/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0663 - accuracy: 0.9923 - val_loss: 1.0757 - val_accuracy: 0.7050\n",
            "Epoch 20/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9968 - val_loss: 1.1532 - val_accuracy: 0.7000\n",
            "Epoch 21/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9974 - val_loss: 1.1780 - val_accuracy: 0.7100\n",
            "Epoch 22/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9943 - val_loss: 1.2562 - val_accuracy: 0.7100\n",
            "Epoch 23/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9960 - val_loss: 1.2885 - val_accuracy: 0.7000\n",
            "Epoch 24/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9929 - val_loss: 1.3377 - val_accuracy: 0.7000\n",
            "Epoch 25/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9932 - val_loss: 1.3702 - val_accuracy: 0.7150\n",
            "Epoch 26/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9948 - val_loss: 1.3980 - val_accuracy: 0.6750\n",
            "Epoch 27/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9930 - val_loss: 1.3439 - val_accuracy: 0.7050\n",
            "Epoch 28/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 1.2808 - val_accuracy: 0.7000\n",
            "Epoch 29/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9956 - val_loss: 1.3865 - val_accuracy: 0.6900\n",
            "Epoch 30/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 0.7150\n",
            "Epoch 31/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 1.4135 - val_accuracy: 0.7000\n",
            "Epoch 32/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 1.4590 - val_accuracy: 0.7150\n",
            "Epoch 33/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 1.4268 - val_accuracy: 0.7200\n",
            "Epoch 34/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 1.4879 - val_accuracy: 0.7000\n",
            "Epoch 35/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9871 - val_loss: 1.8316 - val_accuracy: 0.6450\n",
            "Epoch 36/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1048 - accuracy: 0.9662 - val_loss: 1.5014 - val_accuracy: 0.6800\n",
            "Epoch 37/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1798 - accuracy: 0.9363 - val_loss: 1.7381 - val_accuracy: 0.6100\n",
            "Epoch 38/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1318 - accuracy: 0.9514 - val_loss: 1.5443 - val_accuracy: 0.6900\n",
            "Epoch 39/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9687 - val_loss: 1.6085 - val_accuracy: 0.6800\n",
            "Epoch 40/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0544 - accuracy: 0.9799 - val_loss: 1.8522 - val_accuracy: 0.6900\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 41/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0972 - accuracy: 0.9762 - val_loss: 1.6838 - val_accuracy: 0.6950\n",
            "Epoch 42/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.5218 - val_accuracy: 0.7100\n",
            "Epoch 43/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5591 - val_accuracy: 0.7000\n",
            "Epoch 44/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5645 - val_accuracy: 0.7050\n",
            "Epoch 45/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5695 - val_accuracy: 0.7050\n",
            "Epoch 46/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5715 - val_accuracy: 0.7050\n",
            "Epoch 47/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5779 - val_accuracy: 0.7050\n",
            "Epoch 48/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5894 - val_accuracy: 0.7100\n",
            "Epoch 49/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5956 - val_accuracy: 0.7100\n",
            "Epoch 50/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.5992 - val_accuracy: 0.7150\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 51/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6017 - val_accuracy: 0.7150\n",
            "Epoch 52/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6063 - val_accuracy: 0.7100\n",
            "Epoch 53/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6090 - val_accuracy: 0.7100\n",
            "Epoch 54/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6116 - val_accuracy: 0.7100\n",
            "Epoch 55/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6152 - val_accuracy: 0.7150\n",
            "Epoch 56/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6186 - val_accuracy: 0.7150\n",
            "Epoch 57/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.7150\n",
            "Epoch 58/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6253 - val_accuracy: 0.7150\n",
            "Epoch 59/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6258 - val_accuracy: 0.7150\n",
            "Epoch 60/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6271 - val_accuracy: 0.7150\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 61/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6299 - val_accuracy: 0.7150\n",
            "Epoch 62/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.7150\n",
            "Epoch 63/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6327 - val_accuracy: 0.7150\n",
            "Epoch 64/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6345 - val_accuracy: 0.7150\n",
            "Epoch 65/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6366 - val_accuracy: 0.7150\n",
            "Epoch 66/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6381 - val_accuracy: 0.7150\n",
            "Epoch 67/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6391 - val_accuracy: 0.7150\n",
            "Epoch 68/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6395 - val_accuracy: 0.7150\n",
            "Epoch 69/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.7150\n",
            "Epoch 70/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6416 - val_accuracy: 0.7150\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 71/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.7150\n",
            "Epoch 72/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6442 - val_accuracy: 0.7150\n",
            "Epoch 73/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6465 - val_accuracy: 0.7200\n",
            "Epoch 74/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6474 - val_accuracy: 0.7200\n",
            "Epoch 75/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6492 - val_accuracy: 0.7250\n",
            "Epoch 76/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.7200\n",
            "Epoch 77/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6505 - val_accuracy: 0.7200\n",
            "Epoch 78/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6524 - val_accuracy: 0.7200\n",
            "Epoch 79/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6538 - val_accuracy: 0.7200\n",
            "Epoch 80/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6543 - val_accuracy: 0.7200\n",
            "Epoch 81/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6556 - val_accuracy: 0.7200\n",
            "Epoch 82/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6569 - val_accuracy: 0.7200\n",
            "Epoch 83/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6580 - val_accuracy: 0.7250\n",
            "Epoch 84/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6596 - val_accuracy: 0.7250\n",
            "Epoch 85/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6613 - val_accuracy: 0.7250\n",
            "Epoch 86/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6621 - val_accuracy: 0.7250\n",
            "Epoch 87/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6643 - val_accuracy: 0.7200\n",
            "Epoch 88/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6648 - val_accuracy: 0.7200\n",
            "Epoch 89/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6660 - val_accuracy: 0.7200\n",
            "Epoch 90/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6668 - val_accuracy: 0.7150\n",
            "Epoch 91/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6683 - val_accuracy: 0.7150\n",
            "Epoch 92/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6696 - val_accuracy: 0.7200\n",
            "Epoch 93/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6704 - val_accuracy: 0.7200\n",
            "Epoch 94/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6719 - val_accuracy: 0.7200\n",
            "Epoch 95/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6741 - val_accuracy: 0.7150\n",
            "Epoch 96/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6767 - val_accuracy: 0.7200\n",
            "Epoch 97/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6770 - val_accuracy: 0.7200\n",
            "Epoch 98/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6776 - val_accuracy: 0.7200\n",
            "Epoch 99/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 9.7598e-04 - accuracy: 1.0000 - val_loss: 1.6795 - val_accuracy: 0.7150\n",
            "Epoch 100/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6806 - val_accuracy: 0.7200\n",
            "Epoch 101/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6819 - val_accuracy: 0.7200\n",
            "Epoch 102/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6833 - val_accuracy: 0.7200\n",
            "Epoch 103/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6843 - val_accuracy: 0.7200\n",
            "Epoch 104/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6851 - val_accuracy: 0.7200\n",
            "Epoch 105/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 9.4683e-04 - accuracy: 1.0000 - val_loss: 1.6869 - val_accuracy: 0.7200\n",
            "Epoch 106/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6874 - val_accuracy: 0.7200\n",
            "Epoch 107/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6891 - val_accuracy: 0.7200\n",
            "Epoch 108/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 9.2755e-04 - accuracy: 1.0000 - val_loss: 1.6908 - val_accuracy: 0.7200\n",
            "Epoch 109/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6923 - val_accuracy: 0.7200\n",
            "Epoch 110/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9.8604e-04 - accuracy: 1.0000 - val_loss: 1.6941 - val_accuracy: 0.7200\n",
            "Epoch 111/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9.1427e-04 - accuracy: 1.0000 - val_loss: 1.6939 - val_accuracy: 0.7200\n",
            "Epoch 112/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9.6349e-04 - accuracy: 1.0000 - val_loss: 1.6956 - val_accuracy: 0.7200\n",
            "Epoch 113/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8.7829e-04 - accuracy: 1.0000 - val_loss: 1.6963 - val_accuracy: 0.7200\n",
            "Epoch 114/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9.6120e-04 - accuracy: 1.0000 - val_loss: 1.6988 - val_accuracy: 0.7200\n",
            "Epoch 115/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9.0089e-04 - accuracy: 1.0000 - val_loss: 1.7005 - val_accuracy: 0.7200\n",
            "Epoch 116/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9.2694e-04 - accuracy: 1.0000 - val_loss: 1.7012 - val_accuracy: 0.7200\n",
            "Epoch 117/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9.1141e-04 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.7150\n",
            "Epoch 118/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8.4630e-04 - accuracy: 1.0000 - val_loss: 1.7045 - val_accuracy: 0.7200\n",
            "Epoch 119/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7.7021e-04 - accuracy: 1.0000 - val_loss: 1.7051 - val_accuracy: 0.7200\n",
            "Epoch 120/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8.8089e-04 - accuracy: 1.0000 - val_loss: 1.7071 - val_accuracy: 0.7150\n",
            "Epoch 121/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8.6624e-04 - accuracy: 1.0000 - val_loss: 1.7090 - val_accuracy: 0.7150\n",
            "Epoch 122/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8.1631e-04 - accuracy: 1.0000 - val_loss: 1.7104 - val_accuracy: 0.7150\n",
            "Epoch 123/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8.0686e-04 - accuracy: 1.0000 - val_loss: 1.7109 - val_accuracy: 0.7150\n",
            "Epoch 124/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8.2348e-04 - accuracy: 1.0000 - val_loss: 1.7134 - val_accuracy: 0.7150\n",
            "Epoch 125/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8.2020e-04 - accuracy: 1.0000 - val_loss: 1.7150 - val_accuracy: 0.7150\n",
            "Epoch 126/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7.7600e-04 - accuracy: 1.0000 - val_loss: 1.7153 - val_accuracy: 0.7150\n",
            "Epoch 127/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7.7379e-04 - accuracy: 1.0000 - val_loss: 1.7177 - val_accuracy: 0.7150\n",
            "Epoch 128/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7.5872e-04 - accuracy: 1.0000 - val_loss: 1.7187 - val_accuracy: 0.7150\n",
            "Epoch 129/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7.5723e-04 - accuracy: 1.0000 - val_loss: 1.7207 - val_accuracy: 0.7150\n",
            "Epoch 130/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7.6055e-04 - accuracy: 1.0000 - val_loss: 1.7212 - val_accuracy: 0.7150\n",
            "Epoch 131/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6.6242e-04 - accuracy: 1.0000 - val_loss: 1.7218 - val_accuracy: 0.7100\n",
            "Epoch 132/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7.8716e-04 - accuracy: 1.0000 - val_loss: 1.7255 - val_accuracy: 0.7150\n",
            "Epoch 133/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6.8894e-04 - accuracy: 1.0000 - val_loss: 1.7272 - val_accuracy: 0.7150\n",
            "Epoch 134/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7.6437e-04 - accuracy: 1.0000 - val_loss: 1.7280 - val_accuracy: 0.7150\n",
            "Epoch 135/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6.8633e-04 - accuracy: 1.0000 - val_loss: 1.7292 - val_accuracy: 0.7150\n",
            "Epoch 136/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7.2386e-04 - accuracy: 1.0000 - val_loss: 1.7321 - val_accuracy: 0.7150\n",
            "Epoch 137/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6.8007e-04 - accuracy: 1.0000 - val_loss: 1.7322 - val_accuracy: 0.7150\n",
            "Epoch 138/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7.2971e-04 - accuracy: 1.0000 - val_loss: 1.7347 - val_accuracy: 0.7150\n",
            "Epoch 139/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6.5875e-04 - accuracy: 1.0000 - val_loss: 1.7378 - val_accuracy: 0.7150\n",
            "Epoch 140/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6.9078e-04 - accuracy: 1.0000 - val_loss: 1.7365 - val_accuracy: 0.7150\n",
            "Epoch 141/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6.8135e-04 - accuracy: 1.0000 - val_loss: 1.7385 - val_accuracy: 0.7150\n",
            "Epoch 142/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7.0462e-04 - accuracy: 1.0000 - val_loss: 1.7383 - val_accuracy: 0.7150\n",
            "Epoch 143/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6.7933e-04 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.7150\n",
            "Epoch 144/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6.5184e-04 - accuracy: 1.0000 - val_loss: 1.7428 - val_accuracy: 0.7150\n",
            "Epoch 145/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6.2428e-04 - accuracy: 1.0000 - val_loss: 1.7450 - val_accuracy: 0.7150\n",
            "Epoch 146/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6.7620e-04 - accuracy: 1.0000 - val_loss: 1.7460 - val_accuracy: 0.7150\n",
            "Epoch 147/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7.0989e-04 - accuracy: 1.0000 - val_loss: 1.7474 - val_accuracy: 0.7150\n",
            "Epoch 148/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6.0818e-04 - accuracy: 1.0000 - val_loss: 1.7501 - val_accuracy: 0.7150\n",
            "Epoch 149/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6.3072e-04 - accuracy: 1.0000 - val_loss: 1.7516 - val_accuracy: 0.7150\n",
            "Epoch 150/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.8825e-04 - accuracy: 1.0000 - val_loss: 1.7534 - val_accuracy: 0.7150\n",
            "Epoch 151/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6.1831e-04 - accuracy: 1.0000 - val_loss: 1.7551 - val_accuracy: 0.7150\n",
            "Epoch 152/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.8982e-04 - accuracy: 1.0000 - val_loss: 1.7561 - val_accuracy: 0.7150\n",
            "Epoch 153/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.7204e-04 - accuracy: 1.0000 - val_loss: 1.7565 - val_accuracy: 0.7150\n",
            "Epoch 154/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5.3922e-04 - accuracy: 1.0000 - val_loss: 1.7583 - val_accuracy: 0.7150\n",
            "Epoch 155/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.4404e-04 - accuracy: 1.0000 - val_loss: 1.7605 - val_accuracy: 0.7150\n",
            "Epoch 156/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.4409e-04 - accuracy: 1.0000 - val_loss: 1.7618 - val_accuracy: 0.7150\n",
            "Epoch 157/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.4922e-04 - accuracy: 1.0000 - val_loss: 1.7629 - val_accuracy: 0.7150\n",
            "Epoch 158/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.7929e-04 - accuracy: 1.0000 - val_loss: 1.7640 - val_accuracy: 0.7150\n",
            "Epoch 159/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5.0815e-04 - accuracy: 1.0000 - val_loss: 1.7678 - val_accuracy: 0.7150\n",
            "Epoch 160/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.3596e-04 - accuracy: 1.0000 - val_loss: 1.7676 - val_accuracy: 0.7150\n",
            "Epoch 161/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5.1856e-04 - accuracy: 1.0000 - val_loss: 1.7699 - val_accuracy: 0.7150\n",
            "Epoch 162/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4.9935e-04 - accuracy: 1.0000 - val_loss: 1.7724 - val_accuracy: 0.7150\n",
            "Epoch 163/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4.8277e-04 - accuracy: 1.0000 - val_loss: 1.7735 - val_accuracy: 0.7150\n",
            "Epoch 164/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4.7974e-04 - accuracy: 1.0000 - val_loss: 1.7745 - val_accuracy: 0.7150\n",
            "Epoch 165/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5.1321e-04 - accuracy: 1.0000 - val_loss: 1.7745 - val_accuracy: 0.7150\n",
            "Epoch 166/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4.7549e-04 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.7150\n",
            "Epoch 167/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.7195e-04 - accuracy: 1.0000 - val_loss: 1.7785 - val_accuracy: 0.7150\n",
            "Epoch 168/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.7775e-04 - accuracy: 1.0000 - val_loss: 1.7806 - val_accuracy: 0.7150\n",
            "Epoch 169/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5.0907e-04 - accuracy: 1.0000 - val_loss: 1.7817 - val_accuracy: 0.7150\n",
            "Epoch 170/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.0688e-04 - accuracy: 1.0000 - val_loss: 1.7845 - val_accuracy: 0.7150\n",
            "Epoch 171/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.0138e-04 - accuracy: 1.0000 - val_loss: 1.7856 - val_accuracy: 0.7150\n",
            "Epoch 172/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.5509e-04 - accuracy: 1.0000 - val_loss: 1.7881 - val_accuracy: 0.7150\n",
            "Epoch 173/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4.5065e-04 - accuracy: 1.0000 - val_loss: 1.7899 - val_accuracy: 0.7150\n",
            "Epoch 174/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4.3871e-04 - accuracy: 1.0000 - val_loss: 1.7914 - val_accuracy: 0.7150\n",
            "Epoch 175/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.7473e-04 - accuracy: 1.0000 - val_loss: 1.7927 - val_accuracy: 0.7200\n",
            "Epoch 176/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.2197e-04 - accuracy: 1.0000 - val_loss: 1.7926 - val_accuracy: 0.7200\n",
            "Epoch 177/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4.2517e-04 - accuracy: 1.0000 - val_loss: 1.7956 - val_accuracy: 0.7200\n",
            "Epoch 178/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4.0325e-04 - accuracy: 1.0000 - val_loss: 1.7964 - val_accuracy: 0.7200\n",
            "Epoch 179/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4.1174e-04 - accuracy: 1.0000 - val_loss: 1.7987 - val_accuracy: 0.7200\n",
            "Epoch 180/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4.1099e-04 - accuracy: 1.0000 - val_loss: 1.8008 - val_accuracy: 0.7200\n",
            "Epoch 181/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 3.8656e-04 - accuracy: 1.0000 - val_loss: 1.8011 - val_accuracy: 0.7200\n",
            "Epoch 182/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4.1532e-04 - accuracy: 1.0000 - val_loss: 1.8031 - val_accuracy: 0.7200\n",
            "Epoch 183/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.3229e-04 - accuracy: 1.0000 - val_loss: 1.8051 - val_accuracy: 0.7200\n",
            "Epoch 184/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.0621e-04 - accuracy: 1.0000 - val_loss: 1.8068 - val_accuracy: 0.7200\n",
            "Epoch 185/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.3613e-04 - accuracy: 1.0000 - val_loss: 1.8074 - val_accuracy: 0.7250\n",
            "Epoch 186/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 3.6998e-04 - accuracy: 1.0000 - val_loss: 1.8096 - val_accuracy: 0.7200\n",
            "Epoch 187/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4.2727e-04 - accuracy: 1.0000 - val_loss: 1.8104 - val_accuracy: 0.7250\n",
            "Epoch 188/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 3.7015e-04 - accuracy: 1.0000 - val_loss: 1.8110 - val_accuracy: 0.7250\n",
            "Epoch 189/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 3.3249e-04 - accuracy: 1.0000 - val_loss: 1.8139 - val_accuracy: 0.7200\n",
            "Epoch 190/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 3.5889e-04 - accuracy: 1.0000 - val_loss: 1.8165 - val_accuracy: 0.7200\n",
            "Epoch 191/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 3.8591e-04 - accuracy: 1.0000 - val_loss: 1.8168 - val_accuracy: 0.7200\n",
            "Epoch 192/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 3.2260e-04 - accuracy: 1.0000 - val_loss: 1.8192 - val_accuracy: 0.7200\n",
            "Epoch 193/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 3.5031e-04 - accuracy: 1.0000 - val_loss: 1.8204 - val_accuracy: 0.7200\n",
            "Epoch 194/200\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.5186e-04 - accuracy: 1.0000 - val_loss: 1.8218 - val_accuracy: 0.7250\n",
            "Epoch 195/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 3.4709e-04 - accuracy: 1.0000 - val_loss: 1.8245 - val_accuracy: 0.7200\n",
            "Epoch 196/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 3.4207e-04 - accuracy: 1.0000 - val_loss: 1.8246 - val_accuracy: 0.7250\n",
            "Epoch 197/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 3.5373e-04 - accuracy: 1.0000 - val_loss: 1.8273 - val_accuracy: 0.7200\n",
            "Epoch 198/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 3.4304e-04 - accuracy: 1.0000 - val_loss: 1.8266 - val_accuracy: 0.7250\n",
            "Epoch 199/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 3.5090e-04 - accuracy: 1.0000 - val_loss: 1.8300 - val_accuracy: 0.7200\n",
            "Epoch 200/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 3.1338e-04 - accuracy: 1.0000 - val_loss: 1.8322 - val_accuracy: 0.7250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsafyzUGpU7O"
      },
      "source": [
        "model.save_weights(\"ANN_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BEBs0yz_pIq"
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"ANN_model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9AFmFjig38o",
        "outputId": "96429bca-f2ef-46ef-91e8-a9d56719ce13"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
        "print('test_acc: ',test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 1.8322 - accuracy: 0.7250\n",
            "test_acc:  0.7250000238418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAbl8uENhDth",
        "outputId": "f358b0d5-d9c4-4873-9801-ec98f8508081"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga537xLqhJek",
        "outputId": "2a6802e0-48b8-4541-aa1a-dda81a884e90"
      },
      "source": [
        "np.argmax(predictions[99])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}